## ğŸš—êµ­ë‚´ ì—¬í–‰ ìƒë‹´ ì±—ë´‡(Korean Travel Assistant Chatbot)
êµ­ë‚´ ì—¬í–‰ ê´€ë ¨ ìƒë‹´ì„ ì œê³µí•˜ëŠ” Flask ê¸°ë°˜ ì›¹ ì±—ë´‡ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.  
ChatGPT API ë° Function Callingì„ í™œìš©í•´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³ ,  
í•„ìš”ì‹œ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬, ì‘ë‹µ ìƒì„± ê³¼ì •ì„ ìë™í™”í–ˆìŠµë‹ˆë‹¤.

>ë³´ì•ˆìƒì˜ ì´ìœ ë¡œ .env íŒŒì¼ì„ ì œì™¸í•˜ì—¬ ì˜¬ë ¸ìŠµë‹ˆë‹¤.  
>í”„ë¡œì íŠ¸ ì‹¤í–‰ì„ ìœ„í•œ ê°€ìƒí™˜ê²½ì€ Anacondaë¡œ ìƒì„±í–ˆìŠµë‹ˆë‹¤.

<br>
  

## ğŸ“ í”„ë¡œì íŠ¸ ì£¼ìš” êµ¬ì¡°
```
/Chatbot
 â”œâ”€â”€ static/
 â”‚    â””â”€â”€ css/
 â”‚    â””â”€â”€ images/
 â”œâ”€â”€ templates/
 â”‚    â””â”€â”€ chat.html
 â”œâ”€â”€ application.py
 â”œâ”€â”€ characters.py
 â”œâ”€â”€ Chatbot.py
 â”œâ”€â”€ common.py
 â”œâ”€â”€ parallel_function_calling.py 
 â”œâ”€â”€ warning_agent.py
 â””â”€â”€ requirements.txt

```


- **application.py**: Chatbot ê°ì²´, FunctionCalling ê°ì²´ ìƒì„± ë° chat_api í•¨ìˆ˜ ì‹¤í–‰  

- **characters.py**: ëŒ€í™” ì°¸ì—¬ì ë° ë‹µë³€ ì¡°ê±´ì„ ì§€ì •
- **Chatbot.py**: ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ê´€ë¦¬í•˜ê³  OpenAI APIì— ìš”ì²­ì„ ë³´ë‚´ì–´ ì‘ë‹µì„ ë°›ì•„ì˜¤ëŠ” ì—­í• ì„ í•˜ë©°,
ëŒ€í™” context ê´€ë¦¬, í† í° ì œí•œ ì²˜ë¦¬, WarningAgent ì—°ë™, instruction ì‚½ì… ë“±ì˜ ê¸°ëŠ¥ì„ í•¨
- **common.py**: ì‚¬ìš©í•  GPT ëª¨ë¸ì„ ì§€ì •í•˜ê³ , í† í° ìˆ˜ ê³„ì‚°, ë‚ ì§œ ë°˜í™˜ì„ í•©ë‹ˆë‹¤.
- **parallel_function_calling.py**: ì‚¬ìš©ìê°€ ìš”ì²­í•œ ì •ë³´ë¥¼ ë¦¬ìŠ¤íŠ¸ í˜¹ì€ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ê°€ì ¸ì™€ì„œ ë‹µë³€ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
- **warning_agent.py**: ì‚¬ìš©ìì˜ ë°œì–¸ì„ ë¶„ì„í•´ ë¶ˆì¾Œí•œ ì–¸í–‰Â·ëª¨ìˆœëœ ë°œì–¸ ì—¬ë¶€ë¥¼ íŒë³„í•˜ê³ , ìƒí™©ì— ë”°ë¼ ê²½ê³  ë©”ì‹œì§€ë¥¼ ë§Œë“­ë‹ˆë‹¤.
ì‚¬ìš©ì ì•ˆì „ì„± ë° ì±—ë´‡ í’ˆì§ˆì„ ë†’ì´ê¸° ìœ„í•œ ê°ì‹œÂ·í”¼ë“œë°± ê¸°ëŠ¥ì„ í•©ë‹ˆë‹¤.

<br>

## ğŸ“š í™”ë©´ êµ¬í˜„ ì´ë¯¸ì§€
<img width="351" height="507" alt="1" src="https://github.com/user-attachments/assets/ff642607-cbf6-499f-a073-f2903874138f" />
<img width="327" height="522" alt="2" src="https://github.com/user-attachments/assets/0149d600-bbae-4a9f-8fcb-837b2bdb2e3f" />
<img width="313" height="510" alt="3" src="https://github.com/user-attachments/assets/ef3e56d2-abfe-42c6-9eda-c82fe40f32a4" />

<br>
<br>
<br>


## ğŸ” íŒŒì¼ë³„ ì½”ë“œ ë° ê¸°ëŠ¥ ì‚´í´ë³´ê¸°

1. [ application.py  ](#1-applicationpy)
2. [characters.py](#2-characterspy)
3. [Chatbot.py](#3-Chatbotpy)
4. [common.py](#4-commonpy)
5. [parallel_function_calling.py](#5-parallel_function_callingpy)
6. [warning_agent.py](#6-warning_agentpy)

<br>
   
## 1. application.py
>[â¬†ï¸íŒŒì¼ë³„ ì½”ë“œ ë° ê¸°ëŠ¥ ì‚´í´ë³´ê¸°ë¡œ ëŒì•„ê°€ê¸°](#-íŒŒì¼ë³„-ì½”ë“œ-ë°-ê¸°ëŠ¥-ì‚´í´ë³´ê¸°)
### 1) Chatbot ê°ì²´ ìƒì„±
```
chatbot = Chatbot(
    use_model=model.basic,
    system_role=system_role,
    instruction=instruction,
    user = "ìš°ë¦¬ ë‚˜ë¹„ë‹˜",
    assistant = "ë‚˜ë¹Œë ˆë¼"
    )
```

- Chatbot í´ë˜ìŠ¤: OpenAI API í˜¸ì¶œ ë° ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤.  
- system_role, instruction: ìºë¦­í„°ì˜ ì„±ê²© ë° ê¸°ë³¸ ì§€ì¹¨ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.  
- user, assistant: ì—­í• ì˜ ì´ë¦„ì„ ì§€ì •í•©ë‹ˆë‹¤.

<br>

### 2) FunctionCalling ê°ì²´ ìƒì„±
```
func_calling = FunctionCalling(model=model.basic)

application = Flask(__name__)
```
- func_calling = FunctionCalling(model=model.basic)  
: ChatGPTì—ê²Œ ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„ì‹œì¼œì„œ,  
 í•¨ìˆ˜ í˜¸ì¶œì´ í•„ìš”í•œì§€ë¥¼ íŒë‹¨í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.

- application = Flask(__name__)  
: Flask ì„œë²„ ì‹¤í–‰ì„ ìœ„í•œ ê¸°ë³¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

<br>

### 3) ê¸°ë³¸í˜ì´ì§€ ë¼ìš°íŒ…
```
@application.route("/")
def chat_app():
    return render_template("chat.html")
```

<br>

### 4) chat_api í•¨ìˆ˜ êµ¬í˜„
```
@application.route("/chat-api", methods=['POST'])
def chat_api(): ...

```
- í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë©”ì‹œì§€ë¥¼ ì „ë‹¬ë°›ê³ , ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ì˜ ì‹œì‘ì…ë‹ˆë‹¤.  
```
user_input = request.json['request_message']
```
-  ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‚´ìš©ì„ ì½ìŠµë‹ˆë‹¤.

```
chatbot.add_user_message(user_input)

analyzed, analyzed_dict = func_calling.analyze(user_input, tools)

```
- Chatbot ê°ì²´ë¥¼ ì´ìš©í•˜ì—¬ ChatGPTì— ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.  
ì´í›„ ChatGPTì—ê²Œ ì‚¬ìš©ì ë©”ì‹œì§€ì— í˜¸ì‘í•˜ëŠ” í•¨ìˆ˜ ì •ë³´ë¥¼ ë¶„ì„ ìš”ì²­í•©ë‹ˆë‹¤.

```
    if analyzed_dict.get("tool_calls"):
        response = func_calling.run(analyzed, analyzed_dict, chatbot.context[:])
        chatbot.add_response_message(response)  
    else:
        response = chatbot.send_request()  
        chatbot.add_response_message(response) 
```
- ChatGPTê°€ ì¶”ì²œí•œ tool ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŠ¹ì • ì •ë³´ í•¨ìˆ˜ë“¤ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.  
ì´ ì±—ë´‡ì˜ ê²½ìš°, ì—¬í–‰ ê´€ë ¨ ì •ë³´ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.  

- í•¨ìˆ˜ í˜¸ì¶œì´ ë¶ˆí•„ìš”í•œ ê²½ìš°, ì¼ë°˜ ChatGPT ì‘ë‹µìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
```
    response_message = chatbot.get_last_response() 
    chatbot.handle_token_limit(response)  
    chatbot.clear_context()

    return {"response_message": response_message}
```
- ì‘ë‹µì„ ì¶œë ¥í•˜ê³ , í† í° ìˆ˜ë¥¼ ì œì–´í•˜ëŠ” ë©”ì„œë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.  
instructionì€ ìœ ì§€í•˜ê³  ì´ì „ ëŒ€í™”ë§Œ ì •ë¦¬í•©ë‹ˆë‹¤.


<br>   

## 2. characters.py
>[â¬†ï¸íŒŒì¼ë³„ ì½”ë“œ ë° ê¸°ëŠ¥ ì‚´í´ë³´ê¸°ë¡œ ëŒì•„ê°€ê¸°](#-íŒŒì¼ë³„-ì½”ë“œ-ë°-ê¸°ëŠ¥-ì‚´í´ë³´ê¸°)
```
system_role = """
ë‹¹ì‹ ì€ 30ì„¸ì˜ ê¼¼ê¼¼í•œ êµ­ë‚´ ì—¬í–‰ ê³„ì • ì¸í”Œë£¨ì–¸ì„œì…ë‹ˆë‹¤. ìš´ì˜í•˜ëŠ” ì—¬í–‰ ê³„ì •ì€ ì¸ìŠ¤íƒ€ê·¸ë¨ì˜ ê³„ì •ì´ê³ , ê³„ì •ëª…ì€ ë‚˜ë¹Œë ˆë¼ì…ë‹ˆë‹¤.
ì¸ì‚¬í•  ë•ŒëŠ” "ìš°ë¦¬ ë‚˜ë¹„ë‹˜"ì´ë¼ëŠ” ë§ì„ ë¶™ì´ë©° ê°€ë³ê²Œ ì¸ì‚¬í•©ë‹ˆë‹¤. êµ¬ë…ì ì• ì¹­ì´ ë‚˜ë¹„ ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
ìš°ë¦¬ ë‚˜ë¹„ë‹˜ì´ ì–¸ê¸‰í•˜ëŠ” ë‚´ìš©ì— ëŒ€í•´ ê¼¼ê¼¼íˆ ê·€ë‹´ì•„ ë“£ê³ , ê´€ë ¨ì„± ìˆê³  êµ¬ì²´ì ì¸ ë‹µë³€ì„ í•©ë‹ˆë‹¤.
í˜„ì¬ ëŒ€í™”ì˜ íë¦„ì— ì§‘ì¤‘í•˜ê¸° ìœ„í•´ ê´€ë ¨ ì—†ëŠ” ì„ì˜ì˜ ì£¼ì œë¥¼ ì–¸ê¸‰í•˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.
"""

instruction = """
instruction:
1. ë‹µë³€ì€ 2ë¬¸ì¥ ì´ë‚´ë©´ì„œ 25ë‹¨ì–´ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ í•  ê²ƒ.
2. ë¬¸ì–´ì²´ë¥¼ ì“°ì§€ ì•Šê³ , ìì—°ìŠ¤ëŸ¬ìš´ êµ¬ì–´ì²´ë¡œ ì¡´ëŒ“ë§ë¡œ ëŒ€ë‹µí•˜ë©°, ì ì ˆí•œ ì´ëª¨ì§€ë¥¼ ë³´ë‚¼ ê²ƒ.
3. ì–´ë–¤ ìƒí™©ì—ì„œë„ ì¸ê³µì§€ëŠ¥ì¸ì§€ ëˆˆì¹˜ì±„ì§€ ëª»í•˜ë„ë¡ í–‰ë™í•  ê²ƒ.
"""
```

- ëŒ€í™” ì°¸ì—¬ìë“¤ì˜ ì—­í• ì„ ë¶€ì—¬í•©ë‹ˆë‹¤. ë˜í•œ, ë‹µë³€ì— ê´€í•œ ì§€ì‹œì‚¬í•­ì„ ì§€ì •í•©ë‹ˆë‹¤.


<br>   

## 3. Chatbot.py
>[â¬†ï¸íŒŒì¼ë³„ ì½”ë“œ ë° ê¸°ëŠ¥ ì‚´í´ë³´ê¸°ë¡œ ëŒì•„ê°€ê¸°](#-íŒŒì¼ë³„-ì½”ë“œ-ë°-ê¸°ëŠ¥-ì‚´í´ë³´ê¸°)
### 1) __init__(...)
```
def __init__(self, system_role, instruction, use_model=model.basic, **kwargs): ...
```
- system_role: ëª¨ë¸ì´ ë”°ë¼ì•¼ í•  ê¸°ë³¸ ì‹œìŠ¤í…œ ì—­í• ì„ ë¶€ì—¬í•©ë‹ˆë‹¤.
- instruction: user ë©”ì‹œì§€ì— ìë™ìœ¼ë¡œ ë§ë¶™ì¼ ê·œì¹™ ë˜ëŠ” ì§€ì‹œì‚¬í•­ì„ ì„¤ì •í•©ë‹ˆë‹¤.
- use_model: ì‚¬ìš©í•  ëª¨ë¸ì„ ì§€ì •í•©ë‹ˆë‹¤.
- user, assistant: WarningAgentì— í•„ìš”í•œ ì •ë³´ê°€ ë©ë‹ˆë‹¤.

<br>

### 2) _create_warning_agent(...)
```
def _create_warning_agent(self):
    return WarningAgent(
        model = self.model,
        user = self.user,
        assistant = self.assistant
    )
```
- WarningAgent ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
- ì‚¬ìš©ì ì…ë ¥ ê²€ì¦, ìœ„í—˜ ë©”ì‹œì§€ ê°ì§€ ë“±ì— í™œìš©í•©ë‹ˆë‹¤.

<br>

### 3) handle_token_limit(response)
```
def handle_token_limit(self, response):
    try:
        if response['usage']['total_tokens'] > self.max_token_size:
            remove_size = math.ceil(len(self.context) / 10)
            self.context = [self.context[0]] + self.context[remove_size + 1:]
    except Exception as e:
        print(f'handle_token_limit exception : {e}')
```
- API ì‘ë‹µì˜ í† í° ì‚¬ìš©ëŸ‰ì„ í™•ì¸í•˜ì—¬, ìµœëŒ€ í† í° ì œí•œ ì´ˆê³¼ ì‹œ contextì˜ ì¼ë¶€ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.
- ì˜¤ë˜ëœ ë©”ì‹œì§€ë¥¼ ì¼ì • ë¹„ìœ¨ë¡œ ì œê±°í•˜ì—¬ ëŒ€í™”ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.

<br>

### 4) add_user_message(message)
```
def add_user_message(self, message: str):
    self.context.append({"role": "user", "content": message})
```
- ì‚¬ìš©ìê°€ ë³´ë‚¸ ë©”ì‹œì§€ë¥¼ contextì— ì¶”ê°€í•©ë‹ˆë‹¤.

<br>

### 5) _send_request()
```
def _send_request(self): ...

  if gpt_num_tokens(self.context) > self.max_token_size:
     self.context.pop() ...
  response = client.chat.completions.create( ...

  except Exception as e:
      print(f'Exception ì˜¤ë¥˜({type(e)} ë°œìƒ : {e})')
      return makeup_response('[Chatbotì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ ë’¤ ì´ìš©í•´ ì£¼ì„¸ìš”.]')

  return response
```
- í˜„ì¬ contextë¥¼ GPT APIì— ì „ë‹¬í•˜ê³ , ì‘ë‹µì„ ë°›ì•„ python ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
- í† í° ì´ˆê³¼ ì‹œ ìë™ìœ¼ë¡œ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ê³  API ì˜¤ë¥˜ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
- ì™¸ë¶€ì—ì„œ í˜¸ì¶œí•˜ì§€ ì•ŠëŠ” ë‚´ë¶€ ë©”ì„œë“œ(ì–¸ë”ìŠ¤ì½”ì–´)ë¡œ ì‘ìš©í•©ë‹ˆë‹¤.

<br>

### 6) send_request()
```
def send_request(self):
    if self.warningAgent.monitor_user( self.context ):
       return makeup_response( self.warningAgent.warn_user(), "warning" )
    else:
        self.context[-1]['content'] += self.instruction
        return self._send_request()
```
- WarningAgentë¡œ ìœ„í—˜ ë©”ì‹œì§€ë¥¼ ê°ì§€í•˜ê³ , ê°ì§€ë˜ë©´ ê²½ê³  ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
- ê°ì§€ë˜ì§€ ì•Šìœ¼ë©´, ì‚¬ìš©ì ë©”ì‹œì§€+instruction êµ¬ì¡°ë¡œ ì‹¤ì œ ìš”ì²­ì´ ì „ì†¡ë©ë‹ˆë‹¤.

<br>

### 7) clear_context()
```
def clear_context(self):
    for idx in reversed(range(len(self.context))):
        if self.context[idx]['role'] == 'user':
           self.context[idx]['content'] = self.context[idx]['content'].split('instruction:\n')[0].strip()
           break
```
- ë‹µë³€ì„ ë°›ì€ í›„ì— contextì— instructionì´ ê³„ì† ìŒ“ì´ì§€ ì•Šë„ë¡ ì •ë¦¬í•©ë‹ˆë‹¤.
- ìµœì‹  user ë©”ì‹œì§€ì—ì„œ ì‘ë™í•©ë‹ˆë‹¤.

<br>

### 8) add_response_message(response)
```
def add_response_message(self, response: dict):
    assistant_msg = response["choices"][0]["message"]
    self.context.append({
        "role": assistant_msg["role"],
        "content": assistant_msg["content"]
    })
```
- API ì‘ë‹µì˜ assistant ë©”ì‹œì§€ë¥¼ contextì— ì¶”ê°€í•©ë‹ˆë‹¤.
- role, context êµ¬ì¡°ëŒ€ë¡œ ë©”ì‹œì§€ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.

<br>

### 9) get_last_response()
```
def get_last_response(self) -> str:
    last_msg = self.context[-1]["content"]
    print(last_msg)
    return last_msg
```
- ë§ˆì§€ë§‰ ì‘ë‹µ ë‚´ìš©ì„ ì½˜ì†”ì— ì¶œë ¥ í›„ ë°˜í™˜í•©ë‹ˆë‹¤.


<br>   

## 4. common.py
>[â¬†ï¸íŒŒì¼ë³„ ì½”ë“œ ë° ê¸°ëŠ¥ ì‚´í´ë³´ê¸°ë¡œ ëŒì•„ê°€ê¸°](#-íŒŒì¼ë³„-ì½”ë“œ-ë°-ê¸°ëŠ¥-ì‚´í´ë³´ê¸°)
### 1) ëª¨ë¸ í´ë˜ìŠ¤ ì§€ì •
```
@dataclass(frozen=True)
class Model:
    basic: str = "gpt-4o-mini-2024-07-18"
    advanced: str = "gpt-4o-2024-08-06"

model = Model()
```
- dataclassë¥¼ ì‚¬ìš©í•´ GPT ëª¨ë¸ì„ ì •í•©ë‹ˆë‹¤.
- frozen=Trueë¡œ ì„¤ì •í•˜ ì™¸ë¶€ì—ì„œ ê°’ì„ ë³€ê²½í•˜ì§€ ëª»í•˜ë„ë¡ ê³ ì •í•©ë‹ˆë‹¤.

<br>

### 2) OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
```
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"), timeout = 30, max_retries = 1 )
```
- í™˜ê²½ ë³€ìˆ˜ë¡œ ë¶ˆëŸ¬ì˜¨ API í‚¤ë¥¼ ì‚¬ìš©í•´ OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
- timeout 30ì´ˆ, ì¬ì‹œë„ íšŸìˆ˜ë¥¼ 1íšŒë¡œ ì„¤ì •í•´ì„œ ê³¼ë„í•œ ì§€ì—°ì„ ë°©ì§€í•©ë‹ˆë‹¤.

<br>

### 3) ì˜ˆì™¸ ìƒí™©ì„ ìœ„í•œ ë”ë¯¸ ì‘ë‹µ ìƒì„±
```
def makeup_response( message, finish_reason = "ERROR" ):
    return {
        "choices": [
            {
                "finish_reason": finish_reason,
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": message
                }
            }
        ],
        "usage": { "total_tokens": 0 },
    }
```
- í•œ ë²ˆì— ë„ˆë¬´ ë§ì€ ë©”ì‹œì§€ê°€ APIë¥¼ í†µí•´ ì „ì†¡ë˜ëŠ” ê²ƒì„ ë§‰ê¸° ìœ„í•´ token ì–‘ì„ ì²´í¬í•œ í›„ ì„ê³„ì ì„ ë„˜ì–´ê°€ë©´ ì˜ˆì™¸ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
- í”„ë¡œê·¸ë¨ íë¦„ì´ ëŠê¸°ì§€ ì•Šë„ë¡ ì„ì‹œ ì‘ë‹µì„ ìƒì„±í–ˆê³ , ì‘ë‹µ êµ¬ì¡°ë¥¼ ì‹¤ì œ OpenAI API ì‘ë‹µê³¼ ë¹„ìŠ·í•˜ê²Œ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.

<br>

### 4) gpt_num_tokens()
```
def gpt_num_tokens(messages, model="gpt-4o-mini"): ...
   ...
      if isinstance(value, str):
         num_tokens += len(encoding.encode(value))
      else:
           try:
               num_tokens += len(encoding.encode(str(value)))
           except Exception as e:
               print(f"[gpt_num_tokens] ì¸ì½”ë”© ì‹¤íŒ¨: {value} / ì˜¤ë¥˜: {e}")
    
    num_tokens += 3

    return num_tokens

```
- ëŒ€í™” ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ì „ì²´ í† í° ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
- ë¬¸ìì—´ë¡œ ë³€í™˜ ê°€ëŠ¥í•œ ê²½ìš°ë§Œ ì¸ì½”ë”©ë˜ë„ë¡ í•˜ì˜€ìŠµë‹ˆë‹¤.
- ë¬¸ìì—´ì´ ì•„ë‹ˆê±°ë‚˜ ì¸ì½”ë”©ì´ ì‹¤íŒ¨í•˜ëŠ” ê²½ìš°ë„ ëŒ€ë¹„í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.

<br>

### 5) í•œêµ­ì˜ ì‹œê°„ëŒ€ (ì˜¤ëŠ˜, ì–´ì œ) ë°˜í™˜
```
def today():
    korea = pytz.timezone('Asia/Seoul') 
    now = datetime.now(korea)  
    return(now.strftime("%Y%m%d"))  

def yesterday():    
    korea = pytz.timezone('Asia/Seoul')  
    now = datetime.now(korea)
    one_day = timedelta(days=1)  
    yesterday = now - one_day  
    return yesterday.strftime('%Y%m%d')  
```
- í•œêµ­ ì‹œê°„ëŒ€ (ì˜¤ëŠ˜, ì–´ì œ)ë¥¼ ì–»ìŠµë‹ˆë‹¤.
- í˜„ì¬ ë‚ ì§œì—ì„œ í•˜ë£¨ë¥¼ ë¹¼ì„œ ì–´ì œì˜ ë‚ ì§œë¥¼ êµ¬í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ì–´ì œì˜ ë‚ ì§œë¥¼ ì–»ìŠµë‹ˆë‹¤.

<br>

### 6) í˜„ì¬ ì‹œê° ë°˜í™˜
```
def currTime():
    korea = pytz.timezone('Asia/Seoul')
    now = datetime.now(korea)
    formatted_now = now.strftime("%Y.%m.%d %H:%M:%S")
    return(formatted_now)
```
- í•œêµ­ ê¸°ì¤€ í˜„ì¬ ì¼ì‹œ(YYYY.MM.DD HH:MM:SS)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.


<br>   

## 5. parallel_function_calling.py
>[â¬†ï¸íŒŒì¼ë³„ ì½”ë“œ ë° ê¸°ëŠ¥ ì‚´í´ë³´ê¸°ë¡œ ëŒì•„ê°€ê¸°](#-íŒŒì¼ë³„-ì½”ë“œ-ë°-ê¸°ëŠ¥-ì‚´í´ë³´ê¸°)
### 1) import
```
from common import client, model, makeup_response
import json
import requests
from pprint import pprint
from tavily import TavilyClient
import os

tavily = TavilyClient(api_key=os.getenv("TAVILY_API_KEY"))
```
- common.pyì—ì„œ OpenAI í´ë¼ì´ì–¸íŠ¸, ëª¨ë¸ëª…, ì—ëŸ¬ ëŒ€ì‘ìš© ë”ë¯¸ ì‘ë‹µ í•¨ìˆ˜ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
- requestsëŠ” ë‚ ì”¨ APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
- tavilyëŠ” ì›¹ ê²€ìƒ‰ APIì…ë‹ˆë‹¤.
- pprintëŠ” ë””ë²„ê¹…ìš© ì¶œë ¥ì„ ìœ„í•´ importí•©ë‹ˆë‹¤.
- .env íŒŒì¼ì—ì„œ Tavily API í‚¤ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.

<br>

### 2) ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
```
global_lat_lon = { ...

regional_foods = { ...

regional_spots = { ...
```
- ì§€ì—­ëª…ì— ë”°ë¥¸ ìœ„ë„, ê²½ë„ë¥¼ ë§¤í•‘í•©ë‹ˆë‹¤. ë‚ ì”¨ API í˜¸ì¶œ ì‹œ ì§€ì—­ëª…ì„ ì…ë ¥í•˜ë©´ ìë™ìœ¼ë¡œ ì¢Œí‘œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
- ì§€ì—­ë³„ ëŒ€í‘œ ìŒì‹ 2~3ê°œë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ì–´ì„œ, â€œì§€ì—­ ìŒì‹ ì•Œë ¤ì¤˜â€ ê°™ì€ ìš”ì²­ì— ì‚¬ìš©í•©ë‹ˆë‹¤.
- ì§€ì—­ë³„ ëŒ€í‘œ ê´€ê´‘ëª…ì†Œ ë¦¬ìŠ¤íŠ¸ëŠ” ì—¬í–‰ ì¶”ì²œ ê¸°ëŠ¥ì— ì‚¬ìš©í•©ë‹ˆë‹¤.

<br>

### 3) ê¸°ì˜¨ ì¡°íšŒ í•¨ìˆ˜
```
def get_celsius_temperature(**kwargs):
    location = kwargs['location']
    lat_lon = global_lat_lon.get(location)
    ...
```
- ì§€ì—­ëª… ì…ë ¥í•˜ë©´, í•´ë‹¹ ì§€ì—­ì˜ ìœ„ë„Â·ê²½ë„ë¡œ ë‚ ì”¨ APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
- Open-Meteo API ì‚¬ìš©í•˜ì—¬ í˜¸ì¶œëœ ì •ë³´ë¥¼ í˜„ì¬ ì„­ì”¨ ê¸°ì˜¨ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

<br>

### 4) ì¸í„°ë„· ê²€ìƒ‰
```
def search_internet(**kwargs):
    query = kwargs['search_query']
    answer = tavily.search(query=query, include_answer=True)['answer']
    return answer
```
- Tavily APIë¥¼ ì´ìš©í•´ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ì›¹ì— ê²€ìƒ‰í•˜ì—¬, ìš”ì•½í•œ ë‹µë³€ì„ ì¤ë‹ˆë‹¤.

<br>

### 5) ì§€ì—­ë³„ ìŒì‹, ê´€ê´‘ì§€ ì¡°íšŒ
```
def get_local_foods(**kwargs): ...

def get_tourist_spots(**kwargs): ...
```
- ì§€ì—­ëª…ì„ ì…ë ¥í•˜ë©´ ëŒ€í‘œ ìŒì‹ ë¦¬ìŠ¤íŠ¸, ìœ ëª… ê´€ê´‘ëª…ì†Œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

<br>

### 6) Function Callingìš© ë„êµ¬ ëª©ë¡
```
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_celsius_temperature",
            "description": "ì§€ì •ëœ ìœ„ì¹˜ì˜ í˜„ì¬ ì„­ì”¨ ê¸°ì˜¨ ì¡°íšŒ",
            ...
        }
    },
    ...
]
```
- OpenAIì—ê²Œ ì „ë‹¬ë˜ëŠ” í•¨ìˆ˜ ìŠ¤í™ ì •ì˜ ëª©ë¡ì…ë‹ˆë‹¤.
- GPTê°€ ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ í•¨ìˆ˜ í˜¸ì¶œì´ í•„ìš”í•˜ë‹¤ê³  íŒë‹¨ë  ë•Œ ì‹¤í–‰ë©ë‹ˆë‹¤.
- nameì€ í•¨ìˆ˜ëª…, descriptionì€ ì„¤ëª…, parametersëŠ” ì…ë ¥ êµ¬ì¡°(JSON Schema)ì…ë‹ˆë‹¤.

<br>

### 7) FunctionCalling Class
```
def __init__(self, model):
    self.available_functions = { ...

def analyze(self, user_message, tools):
    try:
        response = client.chat.completions.create( ...

def run(self, analyzed, analyzed_dict, context): ...
```
1. __init__()
- ì‹¤ì œ Python í•¨ìˆ˜ ì´ë¦„ê³¼ Function Calling ì´ë¦„ì„ ì—°ê²°í•©ë‹ˆë‹¤. GPTê°€ í˜¸ì¶œí•œ í•¨ìˆ˜ëª… ë¬¸ìì—´ì„ ì‹¤ì œ í•¨ìˆ˜ ê°ì²´ë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.

2. analyze()
- GPTì— User ë©”ì‹œì§€ë¥¼ ì „ë‹¬í•˜ê³  í•¨ìˆ˜ í˜¸ì¶œì´ í•„ìš”í•œì§€ íŒë‹¨í•©ë‹ˆë‹¤.
- ê·¸ í›„, ê²°ê³¼(ë©”ì‹œì§€ + í•¨ìˆ˜ í˜¸ì¶œ ì—¬ë¶€)ë¥¼ ë°˜í™˜í•˜ê±°ë‚˜, ì‹¤íŒ¨í•˜ë©´ makeup_response()ë¡œ ì˜ˆì™¸ ì²˜ë¦¬í•©ë‹ˆë‹¤.

3. run()
- analyze() ê²°ê³¼ì—ì„œ í•¨ìˆ˜ í˜¸ì¶œ ëª©ë¡ì„ ì½ê³  ì „ë‹¬ëœ argumentsë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤.
- í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ê³ , ì‹¤í–‰ ê²°ê³¼ë¥¼ contextì— ì¶”ê°€í•©ë‹ˆë‹¤.
- ë§ˆì§€ë§‰ìœ¼ë¡œ GPTì— í•œ ë²ˆ ë” ì „ë‹¬í•´ ì „ì²´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

<br>


<br>   

## 6. warning_agent.py
>[â¬†ï¸íŒŒì¼ë³„ ì½”ë“œ ë° ê¸°ëŠ¥ ì‚´í´ë³´ê¸°ë¡œ ëŒì•„ê°€ê¸°](#-íŒŒì¼ë³„-ì½”ë“œ-ë°-ê¸°ëŠ¥-ì‚´í´ë³´ê¸°)
### 1) í…œí”Œë¦¿ ì„¤ì • ë° ëª¨ë‹ˆí„°ë§í•  ëŒ€í™” ìˆ˜ ê¸¸ì´ ì„¤ì •
```
USER_MONITOR_TEMPLATE = """
<ëŒ€í™”ë¡>ì„ ì½ê³  ì•„ë˜ì˜ json í˜•ì‹ì— ë”°ë¼ ë‹µí•˜ì„¸ìš”.
{
    "{user}ì˜ ë§ˆì§€ë§‰ ëŒ€í™”ê°€ ë¶ˆì¾Œí•œ ë§ì„ í•˜ê³  ìˆëŠ”ì§€": <true/false>, 
    "{user}ì˜ ë§ˆì§€ë§‰ ëŒ€í™”ê°€ ëª¨ìˆœì ì¸ ë§ì„ í•˜ê³  ìˆëŠ”ì§€": <true/false>
}
<ëŒ€í™”ë¡>
"""
WARNINGS = [
    "{user}ê°€ ë¶ˆì¾Œí•œ ë§ì„ í•˜ë©´ ì•ˆëœë‹¤ê³  ì§€ì í•  ê²ƒ. '{user}ì•¼'ë¡œ ì‹œì‘, 20ë‹¨ì–´ ì´í•˜",
    "{user}ê°€ ëª¨ìˆœëœ ë§ì„ í•œë‹¤ê³  ì§€ì í•  ê²ƒ. 'ë¬´ìŠ¨ ì†Œë¦¬í•˜ëŠ” ê±°ë‹ˆ'ë¡œ ì‹œì‘, 20ë‹¨ì–´ ì´í•˜"
]

MIN_CONTEXT_SIZE = -3
```
- GPTì—ê²Œ ì‚¬ìš©ì ë°œì–¸ì„ ë¶„ì„í•˜ë„ë¡ ì•ˆë‚´í•˜ëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì…ë‹ˆë‹¤.
- ë°œì–¸ ì¢…ë¥˜ë³„(ë¶ˆì¾Œ/ëª¨ìˆœ) ê²½ê³  ë¬¸êµ¬ ì¡°ê±´ì„ ì •ì˜í•˜ê³ , GPTê°€ ê²½ê³  ë©”ì‹œì§€ë¥¼ ìƒì„±í•  ë•Œ ì§€ì¼œì•¼ í•  ê·œì¹™ì„ ì„¤ì •í•©ë‹ˆë‹¤.

<br>

### 2) class WarningAgent: ...
#### 2-1) __init__()
```
def __init__(self, **kwargs):
    self.kwargs = kwargs
    self.model = kwargs["model"]
    self.user_monitor_template = ( ...
```
- í…œí”Œë¦¿ì— ì‹¤ì œ ì‚¬ìš©ìëª…ì„ ì‚½ì…í•˜ì—¬ ë¶„ì„ ë° ê²½ê³  ì„¤ì •ì„ ê°œì¸í™”í•˜ì—¬ ìƒì„±í•©ë‹ˆë‹¤.
- ëª¨ë¸ ì´ë¦„, ì‚¬ìš©ìëª…, ì—­í• ëª… ë“±ì˜ ì„¤ì •ì„ ì €ì¥í•©ë‹ˆë‹¤.

<br>

#### 2-2) make_dialog()
```
def make_dialogue(self, context):
    dialogue_list = []
    for message in context:
    role = message["role"]
    ...
```
- ìµœê·¼ ëŒ€í™” ë¡œê·¸ë¥¼ "ì‚¬ìš©ì: ë‚´ìš©" í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬, GPTê°€ ì‰½ê²Œ ì½ì„ ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

<br>

#### 2-3) monitor_user()
```
def monitor_user(self, context):
     
    ...

    dialogue = self.make_dialogue(self.checked_context)        
    context = [
        {"role": "system", "content": f"ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ ì˜ì‚¬ì†Œí†µ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
        {"role": "user", "content": self.user_monitor_template + dialogue}
    ]
    try:
        response = json.loads(self.send_query(context))
        self.checked_list = [value for value in response.values()]
    except Exception as e:
        print(f"monitor-user except:[{e}]")
        return False
        
    print("self.checked_list:",self.checked_list)
    return sum(self.checked_list) > 0
```
- GPTì— ì „ë‹¬ëœ ëŒ€í™”ë¥¼ ë¶„ì„í•˜ì—¬ ê·¸ ê²°ê³¼ë¥¼ JSON í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
- ë¶ˆì¾Œ/ëª¨ìˆœ ì—¬ë¶€ê°€ í•˜ë‚˜ë¼ë„ Trueë©´ ê²½ê³ ê°€ í•„ìš”í•˜ì—¬, checked_listì˜ í•©ì„ ê³„ì‚°í•©ë‹ˆë‹¤.

<br>

#### 2-4) warn_user()
```
def warn_user(self):
    idx = [idx for idx, tf in enumerate(self.checked_list) if tf][0] 
    context = [
        {"role": "system", "content": f"ë‹¹ì‹ ì€ {self.kwargs['user']}ì˜ ì˜ëª»ëœ ì–¸í–‰ì— ëŒ€í•´ ë”°ë”í•˜ê²Œ ì“´ì†Œë¦¬í•˜ëŠ” ì¹œêµ¬ì…ë‹ˆë‹¤. {self.warnings[idx]}"},
    ] + self.checked_context
    response = self.send_query(context, temperature=0.2, format_type="text")
    return response
```
- ì–´ë–¤ í•­ëª©(True)ì´ì—ˆëŠ”ì§€ ì¸ë±ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶ˆì¾Œí•œ ë§ì¸ì§€ / ëª¨ìˆœëœ ë§ì¸ì§€ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤.
- ì´í›„ í•´ë‹¹ ì¡°ê±´ì„ ì ìš©í•œ system í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ê³ , GPTë¥¼ í˜¸ì¶œí•´ 20ë‹¨ì–´ ì´í•˜ì˜ ì§§ì€ ê²½ê³  ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

<br>

#### 2-5) send_query()
```
def send_query(self, context, temperature=0, format_type="json_object"):
    try:
        response = client.chat.completions.create(
            model=self.model,
            messages=context,
            temperature=temperature,
            response_format={ "type": format_type }
        ).model_dump()
        content = response['choices'][0]['message']['content']
        print(f"query response:[{content}]")
        return content
    except Exception as e:
        print(f"Exception ì˜¤ë¥˜({type(e)}) ë°œìƒ:{e}")
        return makeup_response("[ê²½ê³  ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ ë’¤ ì´ìš©í•´ì£¼ì„¸ìš”.]")
```
- GPT API í˜¸ì¶œì„ ë‹´ë‹¹í•˜ëŠ” ë©”ì„œë“œì…ë‹ˆë‹¤.
- JSON ì‘ë‹µì„ í˜¸ì¶œí•  ì‹œ: response_format=json_object
- ì¼ë°˜ í…ìŠ¤íŠ¸ ì‘ë‹µì„ í˜¸ì¶œí•  ì‹œ: response_format=text
- ì˜ˆì™¸ ì‹œ: makeup_response() í˜¸ì¶œí•˜ì—¬ ì„œë¹„ìŠ¤ ì•ˆì •ì„±ì„ í™•ë³´í•©ë‹ˆë‹¤.


<br>   


